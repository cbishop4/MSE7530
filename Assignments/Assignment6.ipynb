{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "_75EiZOAfm4j",
        "60bohFkKgUTq",
        "W7EIV3QTgZLs",
        "t6DrMztCGZv_",
        "0QjyjFTeCQiB",
        "HlDvNAOwGh1_"
      ],
      "mount_file_id": "1ah5caI-xrvxltkODrS06PNtBJMtqghs7",
      "authorship_tag": "ABX9TyNUZ+uJgpU6d3MyIZQ+z7ru",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cbishop4/MSE7530/blob/main/Assignments/Assignment6final_20251017.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K3mEBxuREPQR"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import skimage as ski\n",
        "import scipy.ndimage as ndi\n",
        "import cv2"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Assignment 6 - MSE 7530\n",
        "The goal of this assignment is to use some of your image processing principles to solve realistic materials science problems.  \n",
        "**Scoring**: Grade for 7530 is taken out of 100 points; 5995 grade is taken out of 125 points"
      ],
      "metadata": {
        "id": "goivy7dFEVpz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### <font color='red'>Important AI Notice for this assignment:\n",
        "In this assignment, you may **not** use generative AI on Question 1. Question 2 requires you to use it. For questions 3 and 4, you may use it as much as you want. However, if you use it, you must clearly indicate how and where you used it, including what prompts you gave it and how you evaluated whether the results made sense. You **are responsible** for understanding how the code ultimately works; it will also be graded for correctness, so if it did something wrong and you let it slide, you are still on the hook. You are welcome to complete questions 3 and 4 without generative AI if you wish. If you use generative AI for anything other than question 2, you **must** include a reflection paragraph at the end about what tasks it was most helpful for, and what its limitations were."
      ],
      "metadata": {
        "id": "KRSkiYyyraF8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Intro and Principles\n",
        "To make the homework questions a bit easier, I am going to provide some examples of every principle that **I** used to solve the questions. Note that there are many approaches to these problems. You may use any approaches that we have learned in class without citation. **If you use an approach that we did not cover in class, you must cite the source you used**. A simple URL is fine; no need for a formal citation."
      ],
      "metadata": {
        "id": "_75EiZOAfm4j"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Most likely, the 3 most helpful packages you may use are scikit-image, scipy.ndimage, and/or openCV (cv2). Any approaches that you find will probably use these packages."
      ],
      "metadata": {
        "id": "i8aKKmUigJ8R"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<font size=5><font color='blue'> **Please Note**: <font color='black'>for most of my demo, I use the colormap 'Grays_r', which displays 1s as white and 0s as black. I changed this from what I was originally using ('Grays') as it seemed more intuitive; I attempted to change them all back to 'Grays_r', but it is possible I missed one or two. If all of a sudden it seems like something switched to inverse, that could be why.  You are welcome to use any spatially uniform colormap you like; please plot the colorbar on any plot you show."
      ],
      "metadata": {
        "id": "9CwgNIxwDz2X"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Concept: Edge detection  \n",
        "Note that the example as given would not get you very far, and you would want to combine these principles with other operations for clear quantitative information."
      ],
      "metadata": {
        "id": "60bohFkKgUTq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Recall that an edge can be detected by using first and second derivatives. For example, I have an image of a thin film I tried to coat, but it didn't evenly cover the surface. I can compute the gradient to find edges:"
      ],
      "metadata": {
        "id": "EamEOT4rNX02"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "film = ski.io.imread('/content/drive/MyDrive/Teaching Files/MatChar_F2025/Examples/HW6/CEB2_s1_4x_1.jpg')\n",
        "film.shape"
      ],
      "metadata": {
        "id": "J3yM9AK3Ozvz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Note that this image has 3 channels (i.e., it is composed of 3 separate 1200x1600 pixel images). This is because it is an RGB image. We didn't learn this in class, but to turn an RGB image to grayscale, the operation is:  \n",
        "$Gray~=~0.2989Red + 0.5870Green + 0.1140Blue$"
      ],
      "metadata": {
        "id": "CpZk48g9PTxm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "There are specific functions (RGBtoGray) that automatically do this, but here for the sake of illustration we will manually do it."
      ],
      "metadata": {
        "id": "24xTHPLXPwlE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "red = film[:,:,0]; green = film[:,:,1]; blue = film[:,:,2]\n",
        "gray = 0.2989 * red + 0.5870 * green + 0.1140 * blue\n",
        "fig, ax = plt.subplots(1,4,figsize=(20,4))\n",
        "ax[0].imshow(red,cmap='Grays_r'); ax[1].imshow(green,cmap='Grays_r'); ax[2].imshow(blue,cmap='Grays_r')\n",
        "ax[3].imshow(gray,cmap='Grays_r')\n",
        "ax[0].set_title('Red Channel'); ax[1].set_title('Green Channel'); ax[2].set_title('Blue Channel')\n",
        "ax[3].set_title('Grayscale Converted')\n",
        "for a in ax:\n",
        "  a.axis('off')"
      ],
      "metadata": {
        "id": "cpLTbgFeP3bo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "To detect edges, we can use the 2D gradient:"
      ],
      "metadata": {
        "id": "Kq2XxHXGQse3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "gray.shape"
      ],
      "metadata": {
        "id": "EpQpXUEuQ6Bp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gradient = np.gradient(gray)\n",
        "fig, ax = plt.subplots(1,3,figsize=(15,4))\n",
        "ax[0].imshow(gradient[0],cmap='Grays_r')\n",
        "ax[1].imshow(gradient[1],cmap='Grays_r')\n",
        "ax[2].imshow(np.sqrt(gradient[0]**2 + gradient[1]**2),cmap='Grays_r')\n",
        "ax[0].set_title('X-component of gradient'); ax[1].set_title('Y-component of gradient'); ax[2].set_title('Magnitude of Gradient')\n",
        "plt.suptitle('np.gradient (2nd derivative) 2D result')"
      ],
      "metadata": {
        "id": "Tv0DvaYZQ2TX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "You can take a linecut of an image to see the intensity values as you move across a specified axis. To do this, you index all (:) of one axis, and a single index of the other. For example, (note that the linecut has been shifted by a constant in intensity to clearly see both)"
      ],
      "metadata": {
        "id": "7k-rSeYaqd0N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mag = np.sqrt(gradient[0]**2 + gradient[1]**2)\n",
        "fig, ax = plt.subplots(1,2,figsize=(15,4))\n",
        "cb = ax[0].imshow(mag, origin='lower',cmap='Grays_r')\n",
        "plt.colorbar(cb,ax=ax[0])\n",
        "ax[0].axvline(500,color='tab:blue')\n",
        "ax[1].plot(mag[:,500]+50,color='tab:blue',label='Vertical linecut')\n",
        "ax[0].axhline(500, color='red')\n",
        "ax[1].plot(mag[500,:],color='red',label='Horizontal Linecut')\n",
        "ax[1].legend()\n",
        "ax[1].set_xlabel('Pixel'); ax[1].set_ylabel('Gradient Magnitude')\n",
        "ax[0].set_title('Gradient Magnitude')"
      ],
      "metadata": {
        "id": "L_v9TaT1qpMI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Alternatively, you can take the linecut right at the beginning and then calculate the 1st and 2nd derivative:"
      ],
      "metadata": {
        "id": "O14XtROprio3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fig, ax = plt.subplots(4,1,figsize=(3,12),sharex=True) # plotted with a common x-axis\n",
        "cb = ax[0].imshow(gray,origin='lower',cmap='Grays_r')\n",
        "plt.colorbar(cb, ax=ax[0])\n",
        "ax[0].axhline(500)\n",
        "lcut = gray[500,:]\n",
        "ax[1].plot(lcut)\n",
        "d1 = np.diff(lcut)\n",
        "ax[2].plot(d1)\n",
        "d2 = np.diff(d1)\n",
        "ax[3].plot(d2)\n",
        "ax[3].set_xlabel('Pixel')\n",
        "ax[1].set_ylabel('Pixel Intensity (I)')\n",
        "ax[2].set_ylabel('dI/dpx')\n",
        "ax[3].set_ylabel('d2I/dpx2')"
      ],
      "metadata": {
        "id": "NJHVXEB1sAjf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "As you can see, these are not very smooth, and would benefit from some pre-processing; you could pre-process the initial image with a smoothing filter, or you could take the linecut and smooth it using Savitzky-Golay or another method, as we did earlier in the class."
      ],
      "metadata": {
        "id": "6vusey1CtK5H"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Concept: Binary morphological operators & example of image walkthrough\n",
        "The way I do an image walkthrough here is roughly how you will want to do it in Question #1."
      ],
      "metadata": {
        "id": "W7EIV3QTgZLs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's say we want to determine the surface coverage of the film. To explain, let's take a zoomed-in look where I explain what you're looking at."
      ],
      "metadata": {
        "id": "9Tf-P4T6HCS1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.imshow(gray[500:800,500:800],cmap='Grays')\n",
        "plt.text(250, 250,'A',fontsize=16, color='red')\n",
        "plt.text(50, 250,'B',fontsize=16, color='red')"
      ],
      "metadata": {
        "id": "37wr6UDQHHib"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The above image is a failed attempt at making a smooth continuous film. The region labeled \"A\" is an area where the film covered; the \"B\" region is where it didn't stick. The white dots in the B region are small beads of liquid on the surface; in the A region they are probably air bubbles, but will count as part of the continuously covered film."
      ],
      "metadata": {
        "id": "K_wvdfKsHmZu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### My Goal is to use image processing functions to determine what percentage of the surface is covered by thin film.  \n",
        "I will use various image processing functions; some have not been covered in class. You **will** want to use Google when you do this; anything you find online is fair game."
      ],
      "metadata": {
        "id": "k7cM4EUuJjCl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert the grayscale image to 8-bit unsigned integer format; necessary for opencv\n",
        "gray_8u = cv2.convertScaleAbs(gray)\n",
        "\n",
        "thresh_gauss = cv2.adaptiveThreshold(gray_8u, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, 101, 15)\n",
        "\n",
        "plt.imshow(thresh_gauss, cmap='Grays_r')\n",
        "plt.title('Adaptive Threshold (Mean)')\n",
        "plt.axis('off'); plt.colorbar()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "hdvkY3SkJ_bB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Above, I used an adaptive threshold to \"even out\" the image. The adaptive threshold was needed because the image had uneven illumination and some smudges; the adaptive filter uses local means rather than a mean over the entire image."
      ],
      "metadata": {
        "id": "Tt8Lc7hMHq1E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "bined = thresh_gauss < 120\n",
        "plt.imshow(bined,cmap='Grays_r')\n",
        "plt.colorbar()"
      ],
      "metadata": {
        "id": "JYRacScMLZA4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here, I picked a binary threshold where the edges, raised droplets, and film defects are white (1s), while the continuous film is mostly black (0s). Since the white areas in the continuous film are very small, I figured it would be easy to erode away those small features while keeping the ones inside the uncoated areas."
      ],
      "metadata": {
        "id": "eUbzZ9taH1pO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# erode this\n",
        "from skimage.morphology import binary_erosion as er\n",
        "\n",
        "eroded = er(bined,footprint=ski.morphology.disk(1))\n",
        "plt.imshow(eroded,cmap='Grays_r')\n",
        "plt.colorbar()\n"
      ],
      "metadata": {
        "id": "COlFXKEJKcBI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "To get rid of the white spots within the continuous film area, I eroded the binary image. I used the skimage morphology disk to create my structuring element, which I print out below."
      ],
      "metadata": {
        "id": "pQ9O87AtIVJV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(ski.morphology.disk(1))"
      ],
      "metadata": {
        "id": "QvzO1uBsIM-2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Other options for structuring elements include arrays of ones (np.ones((3,3))) will create a structuring element that is a 3x3 pixel array of ones; see here (https://scikit-image.org/docs/0.25.x/auto_examples/numpy_operations/plot_structuring_elements.html#sphx-glr-auto-examples-numpy-operations-plot-structuring-elements-py) for different structuring elements (footprints) you can make."
      ],
      "metadata": {
        "id": "RcMcr4C2Iisd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from skimage.morphology import binary_dilation as dil\n",
        "dilated = dil(eroded,footprint=ski.morphology.disk(1))\n",
        "plt.imshow(dilated,cmap='Grays_r')\n",
        "plt.colorbar()"
      ],
      "metadata": {
        "id": "C24_x5apKb_E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dilated the eroded image to see if I erased the holes; while I erased some of the largest ones, others remained. I will try another function to remove small objects next, that I found in the skimage.morphology documentation."
      ],
      "metadata": {
        "id": "BmfbT-tRJFtY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from skimage.morphology import remove_small_objects as rem_objects\n",
        "removed1 = rem_objects(dilated,min_size=20)\n",
        "plt.imshow(removed1,cmap='Grays_r')\n",
        "plt.colorbar()"
      ],
      "metadata": {
        "id": "zfyBCSwYTkFM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "That did a much better job, and left behind the small objects in the uncoated areas so that we can differentiate between areas."
      ],
      "metadata": {
        "id": "FS0UGskmJaku"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "redilate = dil(removed1,footprint=ski.morphology.disk(8))\n",
        "plt.imshow(redilate,cmap='Grays_r')\n",
        "plt.colorbar()"
      ],
      "metadata": {
        "id": "sQTCCdMGJyOe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here I dilated it to fill some of those gaps and make my domains whiter. Here introduced a source of error, because some of them dilated through continuous film."
      ],
      "metadata": {
        "id": "ZyKogHDvQOSB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from skimage.morphology import remove_small_holes as rem_holes\n",
        "removed2 = rem_holes(redilate,area_threshold=1000)\n",
        "plt.imshow(removed2, cmap='Grays_r')\n",
        "plt.colorbar()"
      ],
      "metadata": {
        "id": "iDyNvD-EOwkl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now almost all of the small holes can be removed. The area threshold had to be chosen so that real continuous film sections didn't get fully filled, which did leave behind a few spots that should have been closed. This is another source of error."
      ],
      "metadata": {
        "id": "3xfNjtbvQXLl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "reerode = er(removed2,footprint=ski.morphology.disk(8))\n",
        "plt.imshow(reerode,cmap='Grays_r')\n",
        "plt.colorbar()"
      ],
      "metadata": {
        "id": "x-FdvEA7Nwe8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "In the last step, I eroded it back by the same amount I originally dilated it so that the domains stayed the same size as they began."
      ],
      "metadata": {
        "id": "IvcNlAj3QIB9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<font size=6><font color='blue'> Final check: Mandatory for your Question 1.  \n",
        "Here we check our final answer for a filter against our original image. One filter should mostly show the dewet areas, while the other filter should mostly show continuous film."
      ],
      "metadata": {
        "id": "PIXD3dpzPnxv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fig, ax = plt.subplots(1,2,figsize=(10,4))\n",
        "ax[0].imshow(reerode*gray)\n",
        "ax[1].imshow((1-reerode)*gray)"
      ],
      "metadata": {
        "id": "9QzgU4AwN5Mn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Final point**: I have decided that this is good enough. There are a few areas that have been filled in; this could definitely be improved. However, it seems to be reasonable."
      ],
      "metadata": {
        "id": "Y2n2RicRPlLX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Class review: Image Math"
      ],
      "metadata": {
        "id": "QJEprXB1gXKV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Images can be added, subtracted, multiplied, divided, summed, etc. When you do this with numpy, it operates element-wise."
      ],
      "metadata": {
        "id": "aizjuW-NQn1p"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-cy5VmYiGUAE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Homework Questions"
      ],
      "metadata": {
        "id": "xWF1f50OGV7f"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##<font color='blue'> 1. Threshold this image to make all crystals appear white (1s), and all other areas appear black (0s). (**30 points +5 EC**)\n"
      ],
      "metadata": {
        "id": "t6DrMztCGZv_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Image is at the course Github, and is pulled from https://doi.org/10.5958/0974-4150.2018.00120.7. It is located in the sampledata/HW6/ folder, and is titled \"NeedleCrystals.png\"."
      ],
      "metadata": {
        "id": "-_j1PbezWS8M"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###<font color='blue'> A. Use a series of Image processing steps and explain the rationale for each along the way. 20/20 points for a complete walk-through with reasonable steps, even if you don't get it perfect; +5 EC for using an algorithm to count the separate particles automatically (this would require extending what we did in class). A complete walkthrough entails showing the step and plotting the result at each step, with a following \"text\" box explaining what you did, why, and how it modified the image (qualitatively). See above walkthrough for an example. Finally, you must end with a final check of your filter against your original image, as shown in the walkthrough."
      ],
      "metadata": {
        "id": "X3-0U8jWQyRA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# please use a combination of code and text cells to answer this question"
      ],
      "metadata": {
        "id": "yUhyRLGsTVjR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Please use a combination of code and text cells to answer this question"
      ],
      "metadata": {
        "id": "utDfZN9wTV5a"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### <font color='blue'> B. Identify the step that seemed to introduce the largest amount of error. What about the step made it difficult to avoid that error? (5 points)"
      ],
      "metadata": {
        "id": "sm-2SOrGQ_pv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Please answer in this text cell"
      ],
      "metadata": {
        "id": "idyx7hExTfgT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### <font color='blue'> C. Evaluate the advantages to including a jupyter notebook with a publication.  (5 points)\n",
        "Let's say that the publication quantifies the average crystal size and reports these numbers in the main paper. What possible benefits would there be to the scientific community by adding in a Jupyter notebook in the SI?"
      ],
      "metadata": {
        "id": "1oZdbEYSRQBa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Please answer in this text cell"
      ],
      "metadata": {
        "id": "UXskN6BoTjmx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## <font color='blue'>2. **You must do this problem after you do problem #1**; I can't check this so it is on your honor.  \n",
        "<font color='blue'><font size=5> Use Gemini's \"generate code\" feature, ChatGPT, or a similar generative AI feature to complete the task asked of you in number 1. Show the result, and include the code it used to complete the task. (**10 points**)"
      ],
      "metadata": {
        "id": "0QjyjFTeCQiB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# please use a combination of code and text cells to answer this question"
      ],
      "metadata": {
        "id": "8UhFHsmgUoSj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Please use a combination of code and text cells to answer this question"
      ],
      "metadata": {
        "id": "nwX0DROPUoSk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## <font color='blue'>3. Come up with a procedure to quantify phase transitions in the liquid crystal RM257. At what temperature(s) do phase transitions occur at as this film is heated? Show your work.  (**30 points**)\n",
        "<font color='blue'>Hint: Liquid crystals have different amounts of optical activity depending on their physical state."
      ],
      "metadata": {
        "id": "HlDvNAOwGh1_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<font color='blue'> For the data on this, you will need to go to the Canvas modules and download the folder \"RM257.zip\". You will then need to put in in your Google Drive and work with it from there. This is unpublished experimental data; I'm not sure if we will ever publish it, but I don't want it public on Github right now."
      ],
      "metadata": {
        "id": "51bYiw4qT2Cl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Once it is in your Google Drive, you can load it into a dataframe using the following code (you will need to modify the folder path into wherever you put it in your drive)."
      ],
      "metadata": {
        "id": "sItUYY4lYY7v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import glob as glob\n",
        "import re\n",
        "folder = '/content/drive/MyDrive/Teaching Files/MatChar_F2025/Examples/HW6/RM257'\n",
        "data = {}\n",
        "temps = []\n",
        "for f in glob.glob(f'{folder}/*'):\n",
        "  if f[-10] == '/':\n",
        "    temps.append(float(f[-9:-5]))\n",
        "    data[float(f[-9:-5])] = ski.io.imread(f)\n",
        "  elif f[-11] == '/':\n",
        "    temps.append(float(f[-10:-5]))\n",
        "    data[float(f[-10:-5])] = ski.io.imread(f)\n",
        "temps.sort() # provides us a list of temperatures in ascending order (our dictionary is disorganized)"
      ],
      "metadata": {
        "id": "CzqIf65KbRTb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.imshow(data[temps[3]])\n",
        "plt.title((str(temps[3]) + ' C'))"
      ],
      "metadata": {
        "id": "70BV2k_abX9B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# to loop through every image in the dictionary in order, we could go:\n",
        "for t in temps:\n",
        "  print(f'Maximum pixel intensity at T = {t} C is {np.max(data[t])}')"
      ],
      "metadata": {
        "id": "wYvoZz2_nJlj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We have basically constructed two things above: A dictionary of all of our images, which can be accessed by typing in data[xx.x], where xx.x is the temperature in degrees C, and a list of temperatures in order so that we can more conveniently go through things and possibly plot them."
      ],
      "metadata": {
        "id": "TbC-dn5Onk-8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# please use a combination of code and text cells to answer this question"
      ],
      "metadata": {
        "id": "DiK6LpF8YJjs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Please use a combination of code and text cells to answer this question"
      ],
      "metadata": {
        "id": "dDdJ2xgRYJjs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. <font color='blue'> Determine the crystal growth rate in this system, showing your work. (**30 points**)  \n",
        "<font color='blue'> For full credit, you can quantify the growth rate for a single crystal. For extra credit (5 points), find a way to report a standard deviation in the growth rate over all crystals in the sample. There are $0.2778~\\mu m$ per pixel; each frame is $0.31746 s$ long."
      ],
      "metadata": {
        "id": "bWtX44vZIB9x"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://pubs.acs.org/doi/10.1021/acs.nanolett.4c00620"
      ],
      "metadata": {
        "id": "ng4TQUc-J68k"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Accessing the data"
      ],
      "metadata": {
        "id": "LCfLExWCo266"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! git clone https://github.com/cbishop4/MSE7530"
      ],
      "metadata": {
        "id": "QxZTF_42YARb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "frame_nos = np.linspace(0,125,126,dtype=int)\n",
        "images = np.empty((126, 1032, 1032))\n",
        "for n in frame_nos:\n",
        "  images[n] = ski.io.imread(f'/content/MSE7530/sampledata/HW6/CrystalVideo/frame{n}.jpg')[:,:,0]\n"
      ],
      "metadata": {
        "id": "e3oqE3CeqYwa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.imshow(images[60])"
      ],
      "metadata": {
        "id": "ChKAe1NtGY8j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# please use a combination of code and text cells"
      ],
      "metadata": {
        "id": "e_wrYD3trVAM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Please use a combination of code and text cells."
      ],
      "metadata": {
        "id": "1giy6oOhrRxU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## <font color='blue'> 5. (No points, but **mandatory** if you used AI on anything other than question 2). AI reflection:  \n",
        "<font color='blue'>What tasks was genAI most helpful for, and what were its limitations? You must write at least a paragraph."
      ],
      "metadata": {
        "id": "iD3YT02EtBo6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Please use a text cell to answer this question."
      ],
      "metadata": {
        "id": "O0-HnJxyrJwa"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "e1DRcZAUtW8y"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
