{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyP4WC2/YIIm6Tyx6foW3XVN",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cbishop4/MSE7530/blob/main/ClassNotebooks/Day6_Final.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Lecture 6: Peak-Finding\n",
        "MSE 7530, Fall 2025, Wayne State University  \n",
        "Wednesday, September 17th, 2025  \n",
        "Prof. Camille Bishop"
      ],
      "metadata": {
        "id": "ISPOz6-NZ6Nk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<font size=4>Today we will start talking about finding peaks and pre-processing data.\n",
        "1. SciPy Find Peaks package  \n",
        "2. Pre-processing data with smoothing & filtering data"
      ],
      "metadata": {
        "id": "_GZUNH5LaJEI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<font size=4><font color='blue'>The topics today are broadly referred to as \"signal processing\". </font> Monday, we will bring in some physical techniques to expand your materials characterization toolbox."
      ],
      "metadata": {
        "id": "g66e8sIZanZk"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "09m7qD5ST6TX"
      },
      "source": [
        "## <font color='red'>**(Always Run These First)**</font> Part 0.5: Quick refresher and necessary import cells\n",
        "Every notebook will generally start with all the necessary import cells in one place; here I will import all packages that we used at once."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MPagbos_RLUn"
      },
      "outputs": [],
      "source": [
        "# the standard cell\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mz_I9gjCUlR9"
      },
      "source": [
        "Setting up file access to the class GH Repo and your personal Google Drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s9K5YJ8HUfNR"
      },
      "outputs": [],
      "source": [
        "!git clone https://github.com/cbishop4/MSE7530.git\n",
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Scientific Python (SciPy) Introduction & Importing\n",
        "<font size=4>SciPy is an open-source software heavily used in mathematics, science, and engineering. Since it is so widely used, it has very thorough documentation and support: https://docs.scipy.org/doc/scipy/index.html. It is generally pre-installed in most Python distributions, including Colab, so it doesn't have to be pip installed unless you need a specific version. While you could import scipy like so:\n",
        "\n",
        "```\n",
        "import scipy as sp\n",
        "```\n",
        "<font size=4>However, instead people generally import specific modules from scipy as in the below code cell:\n",
        "\n"
      ],
      "metadata": {
        "id": "pVfuz3BrqZZO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy import signal"
      ],
      "metadata": {
        "id": "20JodWS6qXtr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<font size=4>Today we will be working with the signal processing module. Take a look around the documentation for other modules. We will use many modules through the course of the class.\n",
        "\n"
      ],
      "metadata": {
        "id": "ziZHFVh3rucT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part 1: Finding Peaks"
      ],
      "metadata": {
        "id": "kgXTLBw5usbN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### signal.find_peaks"
      ],
      "metadata": {
        "id": "WyBvuAmOuI4C"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<font size=4>At its base, this function uses a simple algorithm to identify peaks: It returns a peak for every location in which a point is higher than both of its neighbors."
      ],
      "metadata": {
        "id": "RBiQi_6zv3nj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<font size=4>First, let's just use find_peaks on a dataset to see what find_peaks will do with no control."
      ],
      "metadata": {
        "id": "JQncrpmi6LuY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*I have generated \"array1D\" using Gemini's auto-generation, by entering the prompt \"generate a noisy signal with several peaks\""
      ],
      "metadata": {
        "id": "0WKZK_2V5vJd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# generate a noisy signal with several peaks\n",
        "np.random.seed(42)  # for reproducibility\n",
        "x = np.linspace(0, 10, 1000)\n",
        "array1D = (np.sin(x * 3) + 0.5 * np.sin(x * 5) + 0.2 * np.random.randn(len(x))) * 10\n",
        "plt.plot(array1D,label='data')\n",
        "peak_locs = signal.find_peaks(array1D)\n",
        "plt.plot(peak_locs[0], array1D[peak_locs[0]], 'x',label='Peaks')\n",
        "plt.legend()\n",
        "plt.xlabel('Index')\n",
        "plt.ylabel('Intensity')"
      ],
      "metadata": {
        "id": "4wHlHK655ynB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<font color='red'><font size=4> If the above blue signal is experimental data, is calling \"find_peaks\" alone going to be a good choice for interpretation?"
      ],
      "metadata": {
        "id": "qga3YGBT6zjj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<font size=4> See powerpoint for explanation"
      ],
      "metadata": {
        "id": "jiQlCeLJsREm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<font size=4> A fundamental look at the function - our \"basic implementation\""
      ],
      "metadata": {
        "id": "YXwhf0vhv6Gg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "np.random.seed(31)\n",
        "basic_data = (np.random.rand(10)*10).astype(int)\n",
        "print(basic_data)\n",
        "output = signal.find_peaks(basic_data)\n",
        "print(output)"
      ],
      "metadata": {
        "id": "I4xsYnu2wDKQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(basic_data,'-o')\n",
        "plt.xlabel('Index')\n",
        "plt.ylabel('Value')\n",
        "plt.xticks(np.linspace(0,9,10))\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "dRuK7qZcxZgb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<font size=4>We are going to look at the absolute base algorithm for this function to understand what it's doing. As you'll see, we can add aspects later to refine. What we are about to go through is hidden a few layers into the source code; don't worry about exactly where it is. **Goal: to build your algorithmic thinking skills and understand how code processes data, and how that influences your interpretation.** Here, I have written the un-commented code that you would use to find these peaks. I will go through the code line-by-line on the board. I recommend that you do one of two things:  \n",
        "1. Write comments (starting with #) directly on the code below, or  \n",
        "2. Take notes with paper and pencil  \n",
        "<font size=4>Figure out which of these methods is better for your own learning style."
      ],
      "metadata": {
        "id": "2H4gm0gD0KCF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<font size=4><font color='blue'> NOTE: The code below has been substantially modified from its original form. Its original form is written to interface with other functions and C, the programming language that is one step closer to \"computer-speak\". It is re-written here at a level appropriate for this class."
      ],
      "metadata": {
        "id": "_NQ0Qx-9LVE4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = array1D #the array on which we will find peaks\n",
        "\n",
        "midpoints = np.empty(0,dtype=int)\n",
        "left_edges = np.empty(0,dtype=int)\n",
        "right_edges = np.empty(0, dtype=int)\n",
        "\n",
        "i = 1  # Pointer to current sample, first one can't be maxima\n",
        "i_max = x.shape[0] - 1  # Last sample can't be maxima\n",
        "while i < i_max:\n",
        "    # Test if previous sample is smaller\n",
        "    if x[i - 1] < x[i]:\n",
        "        i_ahead = i + 1  # Index to look ahead of current sample\n",
        "\n",
        "        # Find next sample that is unequal to x[i]\n",
        "        while i_ahead < i_max and x[i_ahead] == x[i]:\n",
        "            i_ahead += 1\n",
        "\n",
        "        # Maxima is found if next unequal sample is smaller than x[i]\n",
        "        if x[i_ahead] < x[i]:\n",
        "            left_edges = np.append(left_edges,i)\n",
        "            right_edges = np.append(right_edges,i_ahead-1)\n",
        "            midpoints = np.append(midpoints, (i + i_ahead - 1) // 2)\n",
        "\n",
        "            # Skip samples that can't be maximum\n",
        "            i = i_ahead\n",
        "    i += 1"
      ],
      "metadata": {
        "id": "ebAvFDZMHiHq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<font size=4> Double-check that our code reproduces the results from find_peaks"
      ],
      "metadata": {
        "id": "K6Ucn9GL2O8z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fig, ax = plt.subplots(1,2,figsize=(10,4))\n",
        "for a in ax:\n",
        "  a.plot(array1D,label='data',color='k')\n",
        "  a.plot(peak_locs[0], array1D[peak_locs[0]], 'x',label='SciPy Findpeaks',markersize=8)\n",
        "  a.plot(midpoints,array1D[midpoints],'x',label='Our algorithm',markersize=5)\n",
        "  a.legend()\n",
        "ax[1].set_xlim(400,600)"
      ],
      "metadata": {
        "id": "3IaBR_62FnWf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### <font color='red'>Written exercise: Manually follow the function.\n",
        "<font size=4><font color='red'>You are given an array - $[1, 1, 2, 2, 2, 3, 1, 5, 7, 8, 8, 9, 1]$. Identify the midpoints, left edges, and right edges."
      ],
      "metadata": {
        "id": "A636Mn-KKkOB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Additional find_peaks arguments: height, threshold, distance, prominence, and width.\n",
        "<font size=4>In class today, we will experiment with the argument \"distance\". We will not break it down in detail into the constituent code as we did above. You will experiment with the other parameters in the homework."
      ],
      "metadata": {
        "id": "w69mtdhGLumD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### \"Distance\" parameter\n",
        "<font size=4> Many Python functions/modules have many arguments which are default specified. As an example, here is what the documentation for \"find_peaks\" has:\n",
        "\n",
        "```\n",
        "find_peaks(x, height=None, threshold=None, distance=None, prominence=None,\n",
        "width=None, wlen=None, rel_height=0.5, plateau_size=None)\n",
        "```\n",
        "<font size=4>The function find_peaks has 9 arguments. However, only one argument **needs** to be passed, which is the array on which to find peaks. The rest of the arguments all have **default values** which are set in the definition of the function with = signs. If nothing is entered for these, the code will run whatever the default is. (Note that arguments are often called parameters interchangeably)\n",
        "\n"
      ],
      "metadata": {
        "id": "xdoxGmQSYkz7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<font size=4><font color='blue'> Here we will experiment with the \"distance\" parameter (argument). </font>From the documentation, this parameter is the \"Required minimal horizontal distance (>= 1) in samples between neighbouring peaks. Smaller peaks are removed first until the condition is fulfilled for all remaining peaks.\"  \n",
        "We will continue to use the same noisy data as above, and see what happens as we set different values of the \"distance\" parameter."
      ],
      "metadata": {
        "id": "5L5RYRUKaJ3O"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step-by-step:"
      ],
      "metadata": {
        "id": "n2z89IvSaxhI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(array1D,color='k')\n",
        "peak_locs = signal.find_peaks(array1D)\n",
        "plt.plot(peak_locs[0], array1D[peak_locs[0]], 'x',label='default',markersize=9,markeredgewidth=3,color='cyan')\n",
        "d = 10\n",
        "peak_locs = signal.find_peaks(array1D,distance=d)\n",
        "plt.plot(peak_locs[0], array1D[peak_locs[0]], 'x',label=d,markersize=7,markeredgewidth=2.5,color='tab:orange')\n",
        "d = 50\n",
        "peak_locs = signal.find_peaks(array1D,distance=d)\n",
        "plt.plot(peak_locs[0], array1D[peak_locs[0]], 'x',label=d,markersize=5,markeredgewidth=1.5,color='magenta')\n",
        "plt.legend()\n"
      ],
      "metadata": {
        "id": "AfEIDEbYahmu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<font color='red'> What happens as we increase the distance parameter?  \n",
        "</font>Next, we will plot just the last one we tried."
      ],
      "metadata": {
        "id": "WBCt0G9rcJ1Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(array1D,color='k')\n",
        "d = 50\n",
        "peak_locs = signal.find_peaks(array1D,distance=d)\n",
        "plt.plot(peak_locs[0], array1D[peak_locs[0]], 'x',label=d,markersize=9,markeredgewidth=1.5,color='magenta')\n",
        "plt.legend()"
      ],
      "metadata": {
        "id": "h4SPXu8jcQb-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<font color='red'>How does this improve our peak-finding? Is it good enough yet?"
      ],
      "metadata": {
        "id": "CzXR3TEcck5O"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<font size=4> Smooth data is best for find_peaks. Example: FTIR data from Monday"
      ],
      "metadata": {
        "id": "NBSeQ9_u29tz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# The data we worked with Monday/you're using in your assignment (not background subtracted)\n",
        "file_PS = '/content/MSE7530/sampledata/Polystyrene.csv'\n",
        "PS_loaded = pd.read_csv(file_PS,header=0)"
      ],
      "metadata": {
        "id": "sLROaSNZZD8u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(PS_loaded['Wavenumber'],PS_loaded['Intensity'])\n",
        "plt.xlabel('Wavenumber $(cm^{-1})$ (Plotted reverse from usual)')\n",
        "plt.ylabel('Intensity/Transmission')"
      ],
      "metadata": {
        "id": "0w3cNDZpfYNl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We need to transform it into something where peaks are maxima (you're welcome for most of the answer to one of the assignment 2 questions)"
      ],
      "metadata": {
        "id": "IAmne_VN4Klt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "absorbance = np.log10(1/(PS_loaded['Intensity']))\n",
        "plt.plot(PS_loaded['Wavenumber'],absorbance)\n",
        "plt.xlabel('Wavenumber $(cm^{-1})$ (Plotted reverse from usual)')\n",
        "plt.ylabel('Absorbance')"
      ],
      "metadata": {
        "id": "HXwW1HN039_u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Clearly there are some issues without the background subtraction - but you can make a few thresholding choices in find_peaks and get a pretty good answer:"
      ],
      "metadata": {
        "id": "MmhwxQ-94VPK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "peaks_FTIR = signal.find_peaks(absorbance,height=-0.5)\n",
        "plt.plot(PS_loaded['Wavenumber'],absorbance)\n",
        "plt.plot(PS_loaded['Wavenumber'][peaks_FTIR[0]],absorbance[peaks_FTIR[0]],'x',color='red')"
      ],
      "metadata": {
        "id": "A5Si2X3a4bBl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Without background subtraction, the height threshold is harder to use; you can practice optimizing this with your background-subtracted data from assignment 2, and with other parameters."
      ],
      "metadata": {
        "id": "HPjJuiEQ4u7V"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Pre-processing: Smoothing\n",
        "<font size=4>One issue with find_peaks is that it only looks quite locally for maxima. One approach to addressing this is to smooth the data. Today we will work with a Savitzky-Golay Smoothing filter. In your homework, you will experiment with different filters."
      ],
      "metadata": {
        "id": "vofZESX7ucHm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Simplest filter: Moving average filter  \n",
        "<font size=4> Let's work with a smaller amount of data for the sake of illustration"
      ],
      "metadata": {
        "id": "sRli12x-5eYU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "extra_zoom = array1D[230:300] # takes only the first 30 points of the array\n",
        "plt.plot(extra_zoom,'-o')\n",
        "plt.xlabel('index')\n",
        "plt.ylabel('value')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Cc5xpiCc5muk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can clearly see that there is a trend, but find_peaks would grab some peaks that are really just noise. Let's zoom in even further to illustrate a moving average."
      ],
      "metadata": {
        "id": "8stjiyxk72HL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# code to compute averages; cannot do for the first 2 and last 2 data points\n",
        "averages = np.empty(len(extra_zoom)-5)\n",
        "for x in range(2,len(extra_zoom)-3):\n",
        "  averages[x-2] = np.mean(extra_zoom[x-2:x+2])\n",
        "plt.plot(extra_zoom,'-o',label='data')\n",
        "x_averages = np.linspace(2,len(averages)+2,len(averages))\n",
        "plt.plot(x_averages,averages,'-o',label='rudimentary smooth')\n",
        "plt.xlabel('index')\n",
        "plt.ylabel('value')\n",
        "plt.legend()\n"
      ],
      "metadata": {
        "id": "HipfOIgTA9jD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This is the process of smoothing, though as you can see, it's not very sophisticated and could be very improved"
      ],
      "metadata": {
        "id": "12QuPJPqCy0M"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Scipy Function: Savitzky-Golay Filter\n",
        "A more standard, sophisticated filter is the Savitzky-Golay Filter, which uses local polynomial fits. It has three main parameters: your data, the window length, and the polynomial order"
      ],
      "metadata": {
        "id": "23zHCwBwH0Yz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# changing window length\n",
        "sg_smoothed1 = signal.savgol_filter(extra_zoom,window_length=5,polyorder=3)\n",
        "sg_smoothed2 = signal.savgol_filter(extra_zoom,window_length=15,polyorder=3)\n",
        "sg_smoothed3 = signal.savgol_filter(extra_zoom,window_length=25,polyorder=3)\n",
        "\n",
        "fig, ax = plt.subplots(1,2,figsize=(10,4))\n",
        "ax[0].plot(extra_zoom,'-o',label='data')\n",
        "ax[0].plot(x_averages,averages,'-o',label='rudimentary smooth')\n",
        "\n",
        "ax[1].plot(extra_zoom,'-o',label='data')\n",
        "index_vals = np.linspace(0,len(sg_smoothed1),len(sg_smoothed1))\n",
        "ax[1].plot(index_vals,sg_smoothed1,'-o',label='5')\n",
        "ax[1].plot(index_vals,sg_smoothed2,'-o',label='15')\n",
        "ax[1].plot(index_vals,sg_smoothed3,'-o',label='25',color='cyan')\n",
        "\n",
        "ax[0].set_title('Previous Moving Average Smooth')\n",
        "ax[1].set_title('Savitzky-Golay, Polyorder=3')\n",
        "ax[0].legend()\n",
        "ax[1].legend(title='Window Length')\n",
        "for a in ax:\n",
        "  a.set_xlabel('index')\n",
        "  a.set_ylabel('value')"
      ],
      "metadata": {
        "id": "Uy8ZLRRAahjs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<font color='red'> Which window length seems best?  \n",
        "Your turn: experiment with polynomial order. Copy-paste the above code, and change the polynomial orders while keeping a constant window length."
      ],
      "metadata": {
        "id": "SKczlxcqKw8p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# your code here"
      ],
      "metadata": {
        "id": "NMUCIXAkK9-A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, let's try it for the full dataset:"
      ],
      "metadata": {
        "id": "08QtQI1xKgnh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sg_smoothed1 = signal.savgol_filter(array1D,window_length=5,polyorder=3)\n",
        "sg_smoothed2 = signal.savgol_filter(array1D,window_length=15,polyorder=3)\n",
        "sg_smoothed3 = signal.savgol_filter(array1D,window_length=25,polyorder=3)\n",
        "\n",
        "fig, ax = plt.subplots(1,2,figsize=(10,4))\n",
        "ax[0].plot(array1D,label='data')\n",
        "index_vals = np.linspace(0,len(sg_smoothed1),len(sg_smoothed1))\n",
        "ax[0].plot(index_vals,sg_smoothed1,'-o',markersize=2,label='5')\n",
        "ax[0].plot(index_vals,sg_smoothed2,'-o',markersize=2,label='15')\n",
        "ax[0].plot(index_vals,sg_smoothed3,'-o',markersize=2,label='25',color='cyan')\n",
        "\n",
        "sg_smoothed1 = signal.savgol_filter(array1D,window_length=15,polyorder=1)\n",
        "sg_smoothed2 = signal.savgol_filter(array1D,window_length=15,polyorder=2)\n",
        "sg_smoothed3 = signal.savgol_filter(array1D,window_length=15,polyorder=3)\n",
        "\n",
        "ax[1].plot(array1D,label='data')\n",
        "index_vals = np.linspace(0,len(sg_smoothed1),len(sg_smoothed1))\n",
        "ax[1].plot(index_vals,sg_smoothed1,'-o',markersize=2,label='1')\n",
        "ax[1].plot(index_vals,sg_smoothed2,'-o',markersize=2,label='2')\n",
        "ax[1].plot(index_vals,sg_smoothed3,'-o',markersize=2,label='3',color='cyan')\n",
        "\n",
        "\n",
        "\n",
        "ax[0].set_title('Changing WL, Polyorder 3')\n",
        "ax[1].set_title('Changing Polyorder, WL 15')\n",
        "ax[0].legend()\n",
        "ax[0].legend(title='Window Length')\n",
        "ax[1].legend(title='Poly Order')\n",
        "for a in ax:\n",
        "  a.set_xlabel('index')\n",
        "  a.set_ylabel('value')"
      ],
      "metadata": {
        "id": "b7b9TnWgi_mu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<font size=4> Part of your assignment #3 will be to see how the found peaks change with smoothing procedures. If we have time remaining in class today, let's discuss the approach you will take."
      ],
      "metadata": {
        "id": "CEGto14lOETb"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "0qTjgcYQi_jI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "KXHiwXO0i_gQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "vsEMgPAoi_aB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "0p1OFXKB5Upj"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}